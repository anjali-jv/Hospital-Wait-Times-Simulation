# -*- coding: utf-8 -*-
"""InputModelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oOgjiScCsebzJGLmsjkI_WMTqW51tILr
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html

#Installing required libraries
!pip install -q pandas numpy matplotlib seaborn scipy openpyxl

#Importing required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

"""# **Arrivals**"""

#Arrivals
arrivals = pd.read_csv('https://raw.githubusercontent.com/anjali-jv/Hospital-Wait-Times-Simulation/refs/heads/main/Data_Arrivals.csv')
arrivals.head()

"""# **Arrivals Data**"""

#Arrivals Data csv

# Change the arrivals data into a wide format (days as rows, hours as columns)
arrivals_df = arrivals.rename(columns={'Unnamed: 0': 'Day'})
arrivals_long = pd.melt(arrivals_df, id_vars=['Day'], var_name='Hour', value_name='Arrival_Count')
print("First 5 rows of the reshaped arrivals_long DataFrame:")
print(arrivals_long.head())

# Examine the overall distribution across the hourly arrival counts across all of the days
mean_arrivals = arrivals_long['Arrival_Count'].mean()
median_arrivals = arrivals_long['Arrival_Count'].median()
std_arrivals = arrivals_long['Arrival_Count'].std()

print(f"Overall Arrival Distribution Statistics:")
print(f"  Mean: {mean_arrivals:.2f} arrivals per hour")
print(f"  Median: {median_arrivals:.2f} arrivals per hour")
print(f"  Standard Deviation: {std_arrivals:.2f} arrivals per hour")

# Visualize the overall pattern using a histogram
plt.figure(figsize=(10, 6))
sns.histplot(arrivals_long['Arrival_Count'], bins=range(0, int(arrivals_long['Arrival_Count'].max()) + 2), kde=False)
plt.title('Distribution of Hourly Arrival Counts')
plt.xlabel('Arrival Count')
plt.ylabel('Frequency')
plt.xticks(range(0, int(arrivals_long['Arrival_Count'].max()) + 2, 2))
plt.grid(axis='y', alpha=0.75)
plt.show()

# Grouping the data by hour of data and the arival counts for each hour
hourly_arrival_stats = arrivals_long.groupby('Hour')['Arrival_Count'].agg(
    ['mean', 'median', 'std', 'min', 'max']
).reset_index()

print("Hourly Arrival Statistics:")
print(hourly_arrival_stats.head())

# Visualizing the average arival count per each hour of the day
hour_order = [
    '12am', '1am', '2am', '3am', '4am', '5am', '6am', '7am', '8am', '9am',
    '10am', '11am', '12pm', '1pm', '2pm', '3pm', '4pm', '5pm', '6pm', '7pm',
    '8pm', '9pm', '10pm', '11pm'
]
hourly_arrival_stats['Hour'] = pd.Categorical(hourly_arrival_stats['Hour'], categories=hour_order, ordered=True)
hourly_arrival_stats = hourly_arrival_stats.sort_values('Hour')
print("Hourly Arrival Statistics sorted by chronological hour:")
print(hourly_arrival_stats.head())
plt.figure(figsize=(12, 6))
sns.lineplot(x='Hour', y='mean', data=hourly_arrival_stats, marker='o')
plt.title('Average Hourly Arrival Counts Over a 24-Hour Cycle')
plt.xlabel('Hour of Day')
plt.ylabel('Average Arrival Count')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.75)
plt.tight_layout()
plt.show()

"""Based on the overall arrival count with a mean of 2.98 and an std of 2.45 producing a variance of 6. Since the variance > mean we can assume overdispersion indicating a Negative Binomial distribution to be the most appropriate distribution to model the bed request arrivals. To further support this, the shape of the histogram is right skewed indicative of a Negative Binomial Distribution.

# **Treatment Times**
"""

#Treatment Times csv
treatment_times = pd.read_csv('https://raw.githubusercontent.com/anjali-jv/Hospital-Wait-Times-Simulation/refs/heads/main/Data_TreatmentTimes.csv')
print(f"Loaded: {len(treatment_times)} treatment records")
print(f"\nSpecialties: {treatment_times['Specialty'].unique()}")
print(f"\nSample counts by specialty:")
print(treatment_times['Specialty'].value_counts())

print("\nFirst 10 rows:")
print(treatment_times.head(10))

def fit_distribution(data, specialty_name):
  '''
  This function aims to fit each of the specialties to Exponential, Lognormal, and Gamma
  to find the best fit. It returns a dictionary of the results and the raw data from the csv

  '''
  results = {
      'specialty': specialty_name,
      'n': len(data),
      'mean': np.mean(data),
      'std': np.std(data, ddof=1),
      'min': np.min(data),
      'max': np.max(data),
      'median': np.median(data)
  }
  print(f"\n{'_'*60}")
  print(f"{specialty_name}")
  print(f"{'_'*60}")
  print(f"Sample size: {results['n']}")
  print(f"Mean: {results['mean']:.3f} days")
  print(f"StdDev: {results['std']:.3f} days")
  print(f"Range: [{results['min']:.3f}, {results['max']:.3f}]")

  #exponential
  try:
      loc, scale = stats.expon.fit(data)
      exp_lambda = 1 / scale

      # KS test
      ks_stat, ks_pval = stats.kstest(data, 'expon', args=(loc, scale))

      results['exponential'] = {
          'loc': loc,
          'scale': scale,
          'lambda': exp_lambda,
          'ks_stat': ks_stat,
          'ks_pval': ks_pval
      }
  except Exception as e:
      results['exponential'] = None
      print(f"\n  Exponential: FAILED ({e})")

  #lognormal
  try:
      shape, loc, scale = stats.lognorm.fit(data, floc=0)

      #mu and sigma
      log_data = np.log(data)
      mu = np.mean(log_data)
      sigma = np.std(log_data, ddof=1)

      #KS test
      ks_stat, ks_pval = stats.kstest(data, 'lognorm', args=(shape, loc, scale))

      results['lognormal'] = {
          'shape': shape,
          'loc': loc,
          'scale': scale,
          'mu': mu,
          'sigma': sigma,
          'ks_stat': ks_stat,
          'ks_pval': ks_pval
      }
  except Exception as e:
      results['lognormal'] = None
      print(f"\n  Lognormal: FAILED ({e})")

  #gamma
  try:
      shape, loc, scale = stats.gamma.fit(data, floc=0)
      rate = 1 / scale

      # KS test
      ks_stat, ks_pval = stats.kstest(data, 'gamma', args=(shape, loc, scale))

      results['gamma'] = {
          'shape': shape,
          'loc': loc,
          'scale': scale,
          'rate': rate,
          'ks_stat': ks_stat,
          'ks_pval': ks_pval
      }
  except Exception as e:
      results['gamma'] = None
      print(f"\n  Gamma: FAILED ({e})")

  #best fit determination
  best_dist = None
  best_pval = 0
  for dist_name in ['exponential', 'lognormal', 'gamma']:
      if results.get(dist_name) and results[dist_name]['ks_pval'] > best_pval:
          best_pval = results[dist_name]['ks_pval']
          best_dist = dist_name

  results['best_fit'] = best_dist

  #printing only best fit results
  print(f"\nBest Fit: {best_dist} (p-value = {best_pval:.4f})")

  if best_dist == 'exponential' and results['exponential']:
    params = results['exponential']
    print(f"Parameters:")
    print(f" lambda (rate) = {params['lambda']:.4f}")
    print(f" scale (mean) = {params['scale']:.4f} days")
    #what to write in simio
    print(f" Simio: Random.Exponential({params['scale']:.4f})")
  elif best_dist == 'lognormal' and results['lognormal']:
    params = results['lognormal']
    print(f"Parameters:")
    print(f" mu = {params['mu']:.4f}")
    print(f" sigma = {params['sigma']:.4f}")
    #what to write in simio
    print(f" Simio: Random.Lognormal({params['mu']:.4f}, {params['sigma']:.4f})")
  elif best_dist == 'gamma' and results['gamma']:
    params = results['gamma']
    print(f"Parameters:")
    print(f" shape = {params['shape']:.4f}")
    print(f" scale = {params['scale']:.4f}")
    print(f" rate = {params['rate']:.4f}")
    #what to write in simio
    print(f" Simio(shap, scale): Random.Gamma({params['shape']:.4f}, {params['scale']:.4f})")
    print(f" Simio(shape, rate): Random.Gamma({params['shape']:.4f}, {params['rate']:.4f})")

  return results, data

#Testing for each Speacialty
all_specialty_results = {}

# Get unique specialties
specialties = treatment_times['Specialty'].unique()

print("Treatment Time Analysis of Best Fit Distribution")
print("*"*60)

# Analyze each specialty
for specialty in specialties:
    specialty_data = treatment_times[treatment_times['Specialty'] == specialty]
    times = specialty_data['Treatment Time (Days)'].values

    results, data = fit_distribution(times, specialty)
    all_specialty_results[specialty] = {
        'results': results,
        'data': data
    }

#Creating Plots
#Creating Q-Q Plots
for specialty in all_specialty_results.keys():
  results = all_specialty_results[specialty]['results']
  data = all_specialty_results[specialty]['data']
  best_fit = results['best_fit']

  fig, ax = plt.subplots(figsize=(8, 8))

  # Q-Q plot for best fit only
  if best_fit == 'exponential':
    stats.probplot(data, dist='expon',
                  sparams=(results['exponential']['loc'],
                          results['exponential']['scale']),
                  plot=ax)
    params_text = f"lambda = {results['exponential']['lambda']:.4f}"

  elif best_fit == 'lognormal':
    stats.probplot(data, dist='lognorm',
                  sparams=(results['lognormal']['shape'],
                          results['lognormal']['loc'],
                          results['lognormal']['scale']),
                  plot=ax)
    params_text = f"mu = {results['lognormal']['mu']:.4f}, sigma = {results['lognormal']['sigma']:.4f}"

  elif best_fit == 'gamma':
    stats.probplot(data, dist='gamma',
                  sparams=(results['gamma']['shape'],
                          results['gamma']['loc'],
                          results['gamma']['scale']),
                  plot=ax)
    params_text = f"alpha = {results['gamma']['shape']:.4f}, beta = {results['gamma']['scale']:.4f}"

  ax.set_title(f'{specialty} - Q-Q Plot\n{best_fit.capitalize()} Distribution (Best Fit)',
            fontsize=14, fontweight='bold')
  ax.grid(alpha=0.3, linestyle='--')

  # Add parameter text
  ax.text(0.05, 0.95, f"Parameters:\n{params_text}\nKS p-value: {results[best_fit]['ks_pval']:.4f}",
         transform=ax.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='white', alpha=0.3))

  plt.tight_layout()
  plt.savefig(f'qq_{specialty}.png', dpi=300, bbox_inches='tight')
  plt.show()

"""### Analyzing the Q-Q Plot
Since the data for each of the different specialties falls on the line, we can confidently state that the theoretical distributions assigned to each specialty are correct
"""